{
  "ex-arithmetic": {
    "starterCode": "import torch\n\na = torch.tensor([1, 2, 3, 4])\nb = torch.tensor([5, 6, 7, 8])\n\n# Calcule o dot product manualmente (soma dos produtos)\nresult = ",
    "hints": [
      "Primeiro multiplique os tensores elemento a elemento com *",
      "Depois some todos os elementos com .sum()",
      "result deveria ser 1*5 + 2*6 + 3*7 + 4*8 = 70"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert result == 70, f'Resultado incorreto: esperado 70, obtido {result}'",
        "assert isinstance(result, (int, torch.Tensor)), 'Resultado deve ser um número ou tensor'"
      ]
    },
    "solution": "result = (a * b).sum()"
  },
  "ex-broadcasting": {
    "starterCode": "import torch\n\nmatrix = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n\n# Normalize cada linha para somar 1\nnormalized = ",
    "hints": [
      "Calcule a soma de cada linha com matrix.sum(dim=1, keepdim=True)",
      "Use keepdim=True para manter as dimensões compatíveis com broadcasting",
      "Divida a matriz pela soma das linhas"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert normalized.shape == torch.Size([2, 3]), f'Shape incorreto: esperado (2, 3), obtido {tuple(normalized.shape)}'",
        "assert torch.allclose(normalized.sum(dim=1), torch.ones(2)), 'Cada linha deveria somar 1'"
      ]
    },
    "solution": "normalized = matrix / matrix.sum(dim=1, keepdim=True)"
  },
  "ex-slicing": {
    "starterCode": "import torch\n\nt = torch.arange(1, 17).reshape(4, 4)\nprint('Tensor original:')\nprint(t)\n\n# Extraia a submatriz 2x2 central\ncenter = ",
    "hints": [
      "Para uma matriz 4x4, o centro são as linhas 1 e 2, colunas 1 e 2",
      "Use slicing: t[start:end, start:end]",
      "Lembre-se que índices começam em 0 e o end é exclusivo"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert center.shape == torch.Size([2, 2]), f'Shape incorreto: esperado (2, 2), obtido {tuple(center.shape)}'",
        "assert center[0, 0].item() == 6, f'Elemento [0,0] incorreto: esperado 6, obtido {center[0,0].item()}'",
        "assert center[1, 1].item() == 11, f'Elemento [1,1] incorreto: esperado 11, obtido {center[1,1].item()}'"
      ]
    },
    "solution": "center = t[1:3, 1:3]"
  },
  "ex-mask": {
    "starterCode": "import torch\n\ntorch.manual_seed(42)  # Para reprodutibilidade\nt = torch.randn(5, 5)\nprint('Tensor original:')\nprint(t)\n\n# Substitua valores negativos por zero\nclipped = ",
    "hints": [
      "Primeiro, faça uma cópia do tensor com t.clone()",
      "Crie uma máscara booleana: mask = clipped < 0",
      "Use indexação com a máscara: clipped[mask] = 0",
      "Alternativamente, use torch.clamp(t, min=0)"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert clipped.shape == torch.Size([5, 5]), f'Shape incorreto: esperado (5, 5), obtido {tuple(clipped.shape)}'",
        "assert (clipped >= 0).all(), 'Todos os valores deveriam ser >= 0'",
        "assert clipped.min() == 0 or t.min() >= 0, 'Os valores negativos deveriam virar 0'"
      ]
    },
    "solution": "clipped = t.clone()\nclipped[clipped < 0] = 0"
  },
  "ex-topk-accuracy": {
    "starterCode": "import torch\n\ntorch.manual_seed(42)\nlogits = torch.randn(5, 4)  # 5 amostras, 4 classes\nlabels = torch.tensor([0, 1, 2, 3, 1])  # classes corretas\n\nprint('Logits (5 amostras, 4 classes):')\nprint(logits)\nprint('\\nLabels:', labels)\n\n# Calcule quantas amostras têm a classe correta entre as top-2 predições\n# Dica: use torch.topk() para pegar os índices das 2 maiores classes por amostra\ntop2_correct = ",
    "hints": [
      "Use torch.topk(logits, k=2, dim=1) para pegar os 2 maiores valores por linha",
      "O segundo retorno de topk são os índices das classes",
      "Compare se labels está em algum dos índices top-2",
      "Use (labels.unsqueeze(1) == top2_indices).any(dim=1) para verificar por amostra",
      "Some os True para contar quantas amostras acertaram"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert isinstance(top2_correct, (int, torch.Tensor)), 'top2_correct deve ser um número ou tensor'",
        "assert 0 <= int(top2_correct) <= 5, 'top2_correct deve estar entre 0 e 5'"
      ]
    },
    "solution": "_, top2_indices = torch.topk(logits, k=2, dim=1)\ncorrect_in_top2 = (labels.unsqueeze(1) == top2_indices).any(dim=1)\ntop2_correct = correct_in_top2.sum().item()"
  },
  "ex-normalize-batch": {
    "starterCode": "import torch\n\ntorch.manual_seed(42)\nbatch = torch.randn(32, 10)  # 32 amostras, 10 features\n\nprint('Shape do batch:', batch.shape)\nprint('Média por feature (antes):', batch.mean(dim=0))\nprint('Std por feature (antes):', batch.std(dim=0))\n\n# Normalize para média 0 e std 1 por feature (coluna)\n# Use broadcasting!\nnormalized = ",
    "hints": [
      "Calcule a média por coluna: mean = batch.mean(dim=0)",
      "Calcule o desvio padrão por coluna: std = batch.std(dim=0)",
      "Normalize: normalized = (batch - mean) / std",
      "Broadcasting funciona porque mean e std têm shape (10,) que é compatível com (32, 10)"
    ],
    "validation": {
      "type": "assert",
      "tests": [
        "assert normalized.shape == torch.Size([32, 10]), f'Shape incorreto: esperado (32, 10), obtido {tuple(normalized.shape)}'",
        "assert torch.allclose(normalized.mean(dim=0), torch.zeros(10), atol=1e-5), 'Média por feature deveria ser ≈ 0'",
        "assert torch.allclose(normalized.std(dim=0), torch.ones(10), atol=0.1), 'Std por feature deveria ser ≈ 1'"
      ]
    },
    "solution": "mean = batch.mean(dim=0)\nstd = batch.std(dim=0)\nnormalized = (batch - mean) / std"
  }
}
