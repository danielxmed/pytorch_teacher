---
title: "Grafo Computacional"
order: 6
prerequisites: ["05-autograd-intro"]
estimatedMinutes: 55
pytorchVersion: "2.2"
---

# Grafo Computacional

O PyTorch constr√≥i um **grafo computacional din√¢mico** durante a execu√ß√£o do c√≥digo. Entender esse grafo √© fundamental para usar o autograd efetivamente e debugar problemas relacionados a gradientes.

## O que √© o Grafo Computacional?

### A Met√°fora da Receita

Pense no grafo computacional como uma **receita** que registra todos os passos que voc√™ executou. Cada ingrediente √© um tensor de entrada, cada passo √© uma opera√ß√£o, e o resultado final √© sua sa√≠da.

Quando voc√™ pede para calcular gradientes (`.backward()`), o PyTorch percorre essa receita de tr√°s para frente, descobrindo como cada ingrediente contribuiu para o resultado final.

<CodeCell id="recipe-analogy">
{`import torch

# Ingredientes (tensores de entrada com requires_grad=True)
farinha = torch.tensor([2.0], requires_grad=True)  # "x"
acucar = torch.tensor([1.0], requires_grad=True)   # "y"

# Passos da receita (opera√ß√µes)
passo1 = farinha * 2       # Dobrar a farinha
passo2 = acucar ** 2       # Quadrado do a√ß√∫car
passo3 = passo1 + passo2   # Misturar
resultado = passo3 * 3     # Triplicar

print("Receita executada!")
print(f"resultado = 3 * (2*farinha + a√ß√∫car¬≤)")
print(f"resultado = 3 * (2*{farinha.item()} + {acucar.item()}¬≤) = {resultado.item()}")

# O grafo registrou todos os passos!
print(f"\\ngrafo final: {resultado.grad_fn}")`}
</CodeCell>

### DAG: Grafo Ac√≠clico Dirigido

Tecnicamente, o grafo computacional √© um **DAG** (Directed Acyclic Graph):
- **Dirigido**: As opera√ß√µes fluem em uma dire√ß√£o (entrada ‚Üí sa√≠da)
- **Ac√≠clico**: N√£o h√° ciclos (n√£o volta para tr√°s durante o forward)
- **Grafo**: Estrutura de n√≥s (tensores/opera√ß√µes) e arestas (depend√™ncias)

<CodeCell id="simple-graph">
{`import torch

# Criar tensores de entrada (FOLHAS do grafo)
x = torch.tensor([2.0], requires_grad=True)
y = torch.tensor([3.0], requires_grad=True)

# Opera√ß√µes criam n√≥s no grafo
a = x + y      # N√≥: AddBackward
b = x * y      # N√≥: MulBackward
c = a + b      # N√≥: AddBackward
z = c ** 2     # N√≥: PowBackward (RAIZ do grafo)

print("Estrutura do Grafo:")
print("=" * 40)
print("Folhas (entradas): x, y")
print("N√≥s intermedi√°rios: a, b, c")
print("Raiz (sa√≠da): z")
print(f"\\nz = (x + y + x*y)¬≤")
print(f"z = ({x.item()} + {y.item()} + {x.item()}*{y.item()})¬≤ = {z.item()}")

# Visualiza√ß√£o conceitual:
print("""
\\nVisualizac√£o do Grafo:

      [x]     [y]     <- Folhas (requires_grad=True)
       |\\     /|
       | \\   / |
       |  \\ /  |
       | AddBackward (a=x+y)
       |    |   |
       |    |  MulBackward (b=x*y)
       |    |   |
       |  AddBackward (c=a+b)
       |       |
        PowBackward (z=c¬≤)  <- Raiz
""")`}
</CodeCell>

<Callout type="info">
**Por que entender o grafo?** Quando voc√™ tem problemas com gradientes (None, NaN, etc.), entender a estrutura do grafo ajuda a identificar onde o problema est√° ocorrendo.
</Callout>

## grad_fn: A Porta de Entrada para o Grafo

O atributo `grad_fn` √© a conex√£o entre um tensor e o grafo computacional. Ele referencia a **fun√ß√£o** que criou esse tensor.

<CodeCell id="grad-fn-basics">
{`import torch

x = torch.tensor([2.0], requires_grad=True)

# x √© folha - n√£o tem grad_fn
print(f"x.grad_fn: {x.grad_fn}")  # None

# Opera√ß√µes criam grad_fn
y = x * 3
print(f"y = x * 3")
print(f"y.grad_fn: {y.grad_fn}")  # MulBackward

z = y + 5
print(f"\\nz = y + 5")
print(f"z.grad_fn: {z.grad_fn}")  # AddBackward

w = z ** 2
print(f"\\nw = z ** 2")
print(f"w.grad_fn: {w.grad_fn}")  # PowBackward

# Cada grad_fn sabe como calcular o gradiente de sua opera√ß√£o
print(f"\\nNome da fun√ß√£o: {w.grad_fn.name()}")`}
</CodeCell>

### Inspecionando grad_fn de Diferentes Opera√ß√µes

<CodeCell id="grad-fn-operations">
{`import torch

x = torch.tensor([2.0, 3.0], requires_grad=True)

# Diferentes opera√ß√µes criam diferentes grad_fn
ops = {
    "x + 1": x + 1,
    "x * 2": x * 2,
    "x ** 2": x ** 2,
    "x.sum()": x.sum(),
    "x.mean()": x.mean(),
    "x.exp()": x.exp(),
    "x.sin()": x.sin(),
    "torch.relu(x)": torch.relu(x),
    "x @ x.T": (x.unsqueeze(1) @ x.unsqueeze(0)),  # matmul
}

print("Opera√ß√£o ‚Üí grad_fn")
print("=" * 50)
for name, tensor in ops.items():
    fn_name = tensor.grad_fn.name() if tensor.grad_fn else "None"
    print(f"{name:20} ‚Üí {fn_name}")`}
</CodeCell>

### next_functions: Navegando o Grafo

O atributo `next_functions` permite navegar para tr√°s no grafo, revelando as depend√™ncias:

<CodeCell id="next-functions">
{`import torch

x = torch.tensor([2.0], requires_grad=True)
y = torch.tensor([3.0], requires_grad=True)

# Criar uma cadeia de opera√ß√µes
a = x * y
b = a + x
c = b ** 2

print("Navegando o grafo de c para as folhas:")
print("=" * 50)

# c foi criado por PowBackward
print(f"c.grad_fn: {c.grad_fn}")

# next_functions mostra as depend√™ncias (uma tupla de (grad_fn, index))
print(f"\\nc.grad_fn.next_functions:")
for i, (fn, idx) in enumerate(c.grad_fn.next_functions):
    print(f"  [{i}] {fn} (index: {idx})")

# Podemos continuar navegando
print(f"\\nb.grad_fn.next_functions:")
b_grad_fn = c.grad_fn.next_functions[0][0]  # Primeiro input de PowBackward
for i, (fn, idx) in enumerate(b_grad_fn.next_functions):
    print(f"  [{i}] {fn} (index: {idx})")

# E assim sucessivamente at√© as folhas (AccumulateGrad)
print(f"\\nTensores folha t√™m AccumulateGrad:")`}
</CodeCell>

<Callout type="tip">
`AccumulateGrad` √© o `grad_fn` especial para tensores folha. Ele indica onde os gradientes ser√£o acumulados durante o backward.
</Callout>

## Leaf vs Non-Leaf em Profundidade

### Defini√ß√£o Precisa

<CodeCell id="leaf-definition">
{`import torch

# CASO 1: Tensor criado com requires_grad=True
a = torch.tensor([1.0], requires_grad=True)
print(f"a = torch.tensor(..., requires_grad=True)")
print(f"  is_leaf: {a.is_leaf}, grad_fn: {a.grad_fn}")

# CASO 2: Tensor criado sem requires_grad (padr√£o)
b = torch.tensor([2.0])
print(f"\\nb = torch.tensor(...)")
print(f"  is_leaf: {b.is_leaf}, grad_fn: {b.grad_fn}")

# CASO 3: Resultado de opera√ß√£o com tensor requires_grad
c = a * 2
print(f"\\nc = a * 2 (opera√ß√£o)")
print(f"  is_leaf: {c.is_leaf}, grad_fn: {c.grad_fn}")

# CASO 4: Tensor sem grad ap√≥s opera√ß√£o com tensores sem grad
d = b * 2
print(f"\\nd = b * 2 (b n√£o tem requires_grad)")
print(f"  is_leaf: {d.is_leaf}, grad_fn: {d.grad_fn}")

# CASO 5: Tensor criado com requires_grad mas atualizado in-place depois
e = torch.tensor([3.0], requires_grad=True)
e.data = torch.tensor([4.0])  # Modifica dados sem criar novo tensor
print(f"\\ne ap√≥s modificar .data")
print(f"  is_leaf: {e.is_leaf}, grad_fn: {e.grad_fn}")`}
</CodeCell>

### Tabela de Refer√™ncia: is_leaf

| Situa√ß√£o | is_leaf | grad_fn | requires_grad |
|----------|---------|---------|---------------|
| `torch.tensor([1.0], requires_grad=True)` | True | None | True |
| `torch.tensor([1.0])` | True | None | False |
| `x * 2` (x tem requires_grad) | False | MulBackward | True |
| `x * 2` (x n√£o tem requires_grad) | True | None | False |
| `x.detach()` | True | None | False |

### Por que Apenas Folhas Acumulam Gradientes?

<CodeCell id="why-leaf-grads">
{`import torch

# Imagine uma rede neural: milh√µes de opera√ß√µes intermedi√°rias!
# Guardar gradientes de TODAS seria desperd√≠cio de mem√≥ria

x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)

# Opera√ß√µes intermedi√°rias
y = x * 2      # 3 elementos
z = y ** 2     # 3 elementos
w = z.sum()    # 1 elemento

# Se guard√°ssemos gradientes de y e z:
# - y.grad: 3 floats
# - z.grad: 3 floats
# Em uma rede real: gigabytes de mem√≥ria desperdi√ßada!

w.backward()

print("Ap√≥s backward:")
print(f"x.grad (folha): {x.grad}")      # Armazenado!
print(f"y.grad (intermedi√°rio): {y.grad}")  # None - n√£o armazenado
print(f"z.grad (intermedi√°rio): {z.grad}")  # None - n√£o armazenado

print("\\n‚Üí Economia de mem√≥ria ao n√£o guardar gradientes intermedi√°rios!")`}
</CodeCell>

## retain_grad(): Quando e Por Qu√™

### O Problema

<CodeCell id="retain-grad-problem">
{`import torch

x = torch.tensor([2.0], requires_grad=True)
y = x ** 2      # y = 4
z = y * 3       # z = 12

z.backward()

print("Precisamos do gradiente de y para debugging...")
print(f"y.grad: {y.grad}")  # None! üò¢

# N√£o temos como saber dz/dy diretamente ap√≥s o backward`}
</CodeCell>

### A Solu√ß√£o

<CodeCell id="retain-grad-solution">
{`import torch

x = torch.tensor([2.0], requires_grad=True)
y = x ** 2
y.retain_grad()  # Marcar ANTES do backward!

z = y * 3
z.backward()

print("Agora temos o gradiente de y!")
print(f"x.grad: {x.grad}")  # dz/dx = dz/dy * dy/dx = 3 * 2x = 3 * 4 = 12
print(f"y.grad: {y.grad}")  # dz/dy = 3`}
</CodeCell>

### Casos de Uso para retain_grad

<CodeCell id="retain-grad-use-cases">
{`import torch

print("Casos de uso comuns para retain_grad():")
print("=" * 50)

# 1. Debugging: Encontrar onde gradientes est√£o errados
print("\\n1. DEBUGGING de Gradientes")
x = torch.tensor([1.0], requires_grad=True)
a = x * 2
a.retain_grad()
b = a + 1
b.retain_grad()
c = b ** 2
c.backward()
print(f"   x.grad={x.grad.item()}, a.grad={a.grad.item()}, b.grad={b.grad.item()}")

# 2. An√°lise de Features Intermedi√°rias
print("\\n2. An√°lise de FEATURES Intermedi√°rias")
# (em redes convolucionais, por exemplo)

# 3. Gradient Penalty (ex: WGAN-GP)
print("\\n3. Regulariza√ß√£o de Gradientes")
# Algumas t√©cnicas precisam do gradiente em pontos intermedi√°rios`}
</CodeCell>

<Callout type="warning" title="Cuidado com Mem√≥ria!">
Usar `retain_grad()` em muitos tensores pode consumir muita mem√≥ria. Use apenas quando realmente necess√°rio para debugging ou t√©cnicas espec√≠ficas.
</Callout>

## Controle do Grafo

### detach(): Quebrando o Grafo

O m√©todo `.detach()` cria uma **c√≥pia** do tensor que n√£o est√° conectada ao grafo:

<CodeCell id="detach-deep">
{`import torch

x = torch.tensor([2.0], requires_grad=True)
y = x ** 2

# y est√° conectado ao grafo
print(f"y.requires_grad: {y.requires_grad}")
print(f"y.grad_fn: {y.grad_fn}")

# y_detached N√ÉO est√° conectado
y_detached = y.detach()
print(f"\\ny_detached.requires_grad: {y_detached.requires_grad}")
print(f"y_detached.grad_fn: {y_detached.grad_fn}")

# IMPORTANTE: Compartilham a mesma mem√≥ria!
print(f"\\nCompartilham mem√≥ria: {y.data_ptr() == y_detached.data_ptr()}")

# Opera√ß√µes com y_detached n√£o afetam gradientes de x
z = y_detached * 3  # N√£o conectado a x!
print(f"\\nz.requires_grad: {z.requires_grad}")`}
</CodeCell>

### Casos de Uso para detach()

<CodeCell id="detach-use-cases">
{`import torch

print("Casos de uso comuns para detach():")
print("=" * 50)

# 1. M√©tricas que n√£o devem afetar treinamento
print("\\n1. M√âTRICAS de Avalia√ß√£o")
x = torch.tensor([2.0], requires_grad=True)
y_pred = x ** 2
loss = (y_pred - 4) ** 2

# Calcular m√©trica sem afetar gradientes
metric = y_pred.detach().numpy()
print(f"   M√©trica: {metric[0]}")

# 2. Targets em modelos com m√∫ltiplas partes
print("\\n2. TARGETS Fixos (ex: Q-Learning)")
# target_value = modelo_target(estado).detach()  # N√£o propagar gradiente

# 3. Evitar computa√ß√£o desnecess√°ria
print("\\n3. Reuso de Valores Computados")
# Quando voc√™ precisa do valor mas n√£o do gradiente

# 4. Logging e Visualiza√ß√£o
print("\\n4. LOGGING sem vazamento de mem√≥ria")
values_to_log = []
for i in range(3):
    temp = torch.tensor([float(i)], requires_grad=True)
    result = temp ** 2
    values_to_log.append(result.detach().item())
print(f"   Valores: {values_to_log}")`}
</CodeCell>

### torch.no_grad() vs detach()

<CodeCell id="no-grad-vs-detach-deep">
{`import torch

x = torch.tensor([2.0], requires_grad=True)

# DETACH: Cria tensor desconectado, pode ser usado em qualquer lugar
y_detach = x.detach() * 3
print("detach():")
print(f"  y_detach.requires_grad: {y_detach.requires_grad}")

# NO_GRAD: Context manager, afeta todas opera√ß√µes dentro do bloco
print("\\nno_grad():")
with torch.no_grad():
    y_no_grad = x * 3
    print(f"  y_no_grad.requires_grad: {y_no_grad.requires_grad}")

# Diferen√ßa pr√°tica:
print("\\nDiferen√ßa pr√°tica:")
print("  detach() - Usa quando precisa de UM tensor desconectado")
print("  no_grad() - Usa para BLOCO de opera√ß√µes sem gradientes")

# Composi√ß√£o:
z = x ** 2
with torch.no_grad():
    w = z * 2  # w n√£o rastreia gradientes
    # Mas z ainda est√° conectado a x!

z.backward()  # Funciona! z ainda est√° no grafo
print(f"\\nx.grad: {x.grad}")`}
</CodeCell>

### torch.inference_mode(): Otimiza√ß√£o para Infer√™ncia

<CodeCell id="inference-mode">
{`import torch

x = torch.tensor([2.0], requires_grad=True)

# no_grad: Apenas desabilita gradientes
print("no_grad():")
with torch.no_grad():
    y1 = x * 3
    print(f"  y1.requires_grad: {y1.requires_grad}")

# inference_mode: Desabilita gradientes E otimiza para infer√™ncia
print("\\ninference_mode():")
with torch.inference_mode():
    y2 = x * 3
    print(f"  y2.requires_grad: {y2.requires_grad}")

# inference_mode √© MAIS R√ÅPIDO que no_grad
# Porque faz otimiza√ß√µes adicionais assumindo que voc√™ n√£o vai precisar de gradientes

print("\\n‚Üí Use inference_mode() para infer√™ncia em produ√ß√£o!")
print("‚Üí Use no_grad() quando precisar de mais flexibilidade durante desenvolvimento")`}
</CodeCell>

<Callout type="tip">
**Quando usar cada um:**
- `detach()`: Quando precisa desconectar UM tensor espec√≠fico
- `no_grad()`: Durante valida√ß√£o/teste, update de par√¢metros
- `inference_mode()`: Em produ√ß√£o, para m√°xima performance
</Callout>

## Grafos Din√¢micos vs Est√°ticos

### O Que Significa "Din√¢mico"?

<CodeCell id="dynamic-explained">
{`import torch

# Em PyTorch, o grafo √© reconstru√≠do A CADA forward pass!
x = torch.tensor([1.0], requires_grad=True)

print("Grafo muda baseado em VALORES em tempo de execu√ß√£o:")
print("=" * 50)

for i in range(4):
    # O grafo √© diferente a cada itera√ß√£o!
    if x.item() > 0.5:
        y = x ** 2
        op = "x¬≤"
    else:
        y = x ** 3
        op = "x¬≥"

    y.backward()
    print(f"Iter {i}: x={x.item():.2f}, op={op}, grad={x.grad.item():.2f}")

    # Simular update e zerar gradiente
    with torch.no_grad():
        x -= 0.3 * x.grad
    x.grad.zero_()`}
</CodeCell>

### Vantagens de Grafos Din√¢micos

<CodeCell id="dynamic-advantages">
{`import torch

print("Vantagens de Grafos Din√¢micos:")
print("=" * 50)

# 1. CONTROLE DE FLUXO NATURAL
print("\\n1. Controle de fluxo Python funciona normalmente:")
def dynamic_forward(x, training=True):
    y = x * 2
    if training:
        # Dropout manual (exemplo simplificado)
        mask = torch.rand_like(x) > 0.5
        y = y * mask.float() * 2
    return y.sum()

x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
loss = dynamic_forward(x, training=True)
loss.backward()
print(f"   Gradiente com dropout: {x.grad}")

# 2. RECURS√ÉO NATURAL
print("\\n2. Estruturas recursivas (ex: √°rvores, sequ√™ncias vari√°veis):")

def recursive_sum(x, depth):
    if depth == 0:
        return x
    return x + recursive_sum(x * 0.5, depth - 1)

x = torch.tensor([1.0], requires_grad=True)
y = recursive_sum(x, depth=3)
y.backward()
print(f"   Gradiente de soma recursiva: {x.grad}")

# 3. DEBUGGING F√ÅCIL
print("\\n3. Debugging com print statements funciona!")
def debug_forward(x):
    y = x ** 2
    print(f"   DEBUG: y = {y.item()}")  # Funciona normalmente!
    z = y + 1
    return z

x = torch.tensor([2.0], requires_grad=True)
z = debug_forward(x)
z.backward()
print(f"   Gradiente: {x.grad}")`}
</CodeCell>

### Compara√ß√£o com Grafos Est√°ticos

| Aspecto | Din√¢mico (PyTorch) | Est√°tico (TF 1.x, etc.) |
|---------|-------------------|------------------------|
| Defini√ß√£o | Durante execu√ß√£o | Antes da execu√ß√£o |
| Controle de fluxo | Python nativo | Ops especiais (tf.cond) |
| Debugging | print(), pdb normal | Ferramentas especiais |
| Flexibilidade | Alta | Limitada |
| Otimiza√ß√£o | Em tempo de execu√ß√£o | Pr√©-compila√ß√£o poss√≠vel |
| Uso t√≠pico | Research, prototipagem | Produ√ß√£o otimizada |

<Callout type="info">
**Nota hist√≥rica**: TensorFlow 2.x adotou grafos din√¢micos por padr√£o (eager execution) devido ao sucesso do PyTorch. JAX usa uma abordagem h√≠brida com compila√ß√£o JIT.
</Callout>

## Debugging do Grafo

### Inspecionando _saved_* Attributes

Durante o forward, algumas opera√ß√µes salvam valores intermedi√°rios para usar no backward:

<CodeCell id="saved-tensors">
{`import torch

x = torch.tensor([2.0], requires_grad=True)
y = x ** 2

# A opera√ß√£o Pow salvou o input para calcular o gradiente
# (derivada de x¬≤ √© 2x, ent√£o precisa do valor de x)
print("Valores salvos pela opera√ß√£o PowBackward:")
print(f"  grad_fn: {y.grad_fn}")

# Acessar valores salvos (para debugging)
# Nota: Os nomes dos atributos dependem da opera√ß√£o
try:
    # Para PowBackward, self_ √© o input
    saved = y.grad_fn._saved_self
    print(f"  _saved_self: {saved}")
except AttributeError as e:
    print(f"  (atributo n√£o dispon√≠vel: {e})")

# Exemplo com multiplica√ß√£o
a = torch.tensor([3.0], requires_grad=True)
b = torch.tensor([4.0], requires_grad=True)
c = a * b

print(f"\\nPara MulBackward (c = a * b):")
print(f"  grad_fn: {c.grad_fn}")
# MulBackward precisa de ambos inputs para calcular gradientes`}
</CodeCell>

### Fun√ß√£o para Visualizar o Grafo

<CodeCell id="visualize-graph">
{`import torch

def print_graph(tensor, indent=0):
    """Imprime a estrutura do grafo computacional."""
    prefix = "  " * indent

    if tensor.grad_fn is None:
        if tensor.requires_grad:
            print(f"{prefix}‚îî‚îÄ [LEAF] requires_grad=True")
        else:
            print(f"{prefix}‚îî‚îÄ [LEAF] requires_grad=False")
        return

    print(f"{prefix}‚îî‚îÄ {tensor.grad_fn.name()}")

    for i, (fn, idx) in enumerate(tensor.grad_fn.next_functions):
        if fn is not None:
            # Criar tensor dummy para recurs√£o (hack)
            dummy = torch.zeros(1, requires_grad=True)
            dummy.grad_fn = fn
            # Na verdade, vamos s√≥ imprimir o nome
            if hasattr(fn, 'name'):
                print(f"{prefix}   ‚îî‚îÄ {fn.name()}")
            else:
                print(f"{prefix}   ‚îî‚îÄ {fn}")

# Exemplo de uso
x = torch.tensor([2.0], requires_grad=True)
y = torch.tensor([3.0], requires_grad=True)

z = ((x ** 2) + (y * 2)).sum()

print("Grafo de z = sum(x¬≤ + 2y):")
print_graph(z)`}
</CodeCell>

### Problemas Comuns e Solu√ß√µes

<CodeCell id="common-problems">
{`import torch

print("Problemas Comuns com o Grafo Computacional:")
print("=" * 55)

# PROBLEMA 1: grad_fn √© None inesperadamente
print("\\n1. grad_fn √© None")
x = torch.tensor([1.0])  # Esqueceu requires_grad=True!
y = x * 2
print(f"   x.requires_grad: {x.requires_grad}")
print(f"   y.grad_fn: {y.grad_fn}")
print("   ‚Üí Solu√ß√£o: torch.tensor([1.0], requires_grad=True)")

# PROBLEMA 2: RuntimeError - grafo j√° foi liberado
print("\\n2. 'Trying to backward through the graph a second time'")
x = torch.tensor([1.0], requires_grad=True)
y = x ** 2
y.backward()
try:
    y.backward()  # Erro!
except RuntimeError as e:
    print(f"   Erro: {str(e)[:50]}...")
print("   ‚Üí Solu√ß√£o: use retain_graph=True no primeiro backward")

# PROBLEMA 3: In-place operation quebra o grafo
print("\\n3. 'In-place operation modified tensor needed for gradient'")
x = torch.tensor([1.0], requires_grad=True)
y = x * 2
# y += 1  # Isso pode dar erro durante backward!
print("   ‚Üí Solu√ß√£o: evite opera√ß√µes in-place em tensores do grafo")
print("   ‚Üí Use y = y + 1 ao inv√©s de y += 1")

# PROBLEMA 4: Gradiente acumula quando n√£o deveria
print("\\n4. Gradientes acumulando")
x = torch.tensor([1.0], requires_grad=True)
for i in range(3):
    y = x ** 2
    y.backward()
    print(f"   Iter {i}: x.grad = {x.grad.item()}")
    # x.grad.zero_()  # Deveria zerar!
print("   ‚Üí Solu√ß√£o: sempre zere gradientes entre itera√ß√µes")`}
</CodeCell>

<Callout type="warning">
**Regra de ouro**: Se algo estranho est√° acontecendo com seus gradientes, verifique:
1. `requires_grad` est√° True?
2. O tensor √© folha ou intermedi√°rio?
3. O grafo foi liberado ap√≥s backward?
4. Opera√ß√µes in-place est√£o quebrando o grafo?
</Callout>

## Exerc√≠cios

Teste seu entendimento do grafo computacional com estes exerc√≠cios.

<Exercise id="ex-graph-understand" difficulty="medium">
Dado o c√≥digo abaixo, determine qual ser√° o valor de `x.grad` ap√≥s o backward. Armazene sua previs√£o em `predicted_grad`.

```python
x = torch.tensor([3.0], requires_grad=True)
a = x * 2      # a = 2x
b = a + x      # b = 2x + x = 3x
c = b ** 2     # c = (3x)¬≤ = 9x¬≤
```

A derivada dc/dx usando regra da cadeia √© 18x = 54 em x=3.
</Exercise>

<Exercise id="ex-is-leaf" difficulty="easy">
Crie tr√™s tensores e identifique quais s√£o folhas:
- `a = torch.tensor([1.0], requires_grad=True)` (folha)
- `b = a * 2` (n√£o folha)
- `c = torch.tensor([2.0])` (folha sem grad)

Armazene o resultado de `a.is_leaf`, `b.is_leaf`, `c.is_leaf` nas vari√°veis `a_is_leaf`, `b_is_leaf`, `c_is_leaf`.
</Exercise>

<Exercise id="ex-retain-grad" difficulty="medium">
Use `retain_grad()` para obter o gradiente de um tensor intermedi√°rio. Dado:
- `x = torch.tensor([2.0], requires_grad=True)`
- `y = x ** 3` (queremos o gradiente de y!)
- `z = y * 2`

Obtenha `dy/dx` (armazene em `y_grad`) e verifique que √© `3x¬≤ = 12` para `x=2`.
</Exercise>

<Exercise id="ex-detach-use" difficulty="medium">
Crie uma fun√ß√£o que calcula `y = x¬≤` e tamb√©m retorna `x¬≤` para logging, mas o valor de logging n√£o deve afetar os gradientes. Armazene o valor de logging em `log_value` (deve ser um tensor sem gradientes).
</Exercise>

<Exercise id="ex-navigate-graph" difficulty="hard">
Navegue pelo grafo computacional para encontrar quantas opera√ß√µes existem entre a sa√≠da e as folhas. Dado:
- `x = torch.tensor([1.0], requires_grad=True)`
- `y = x * 2`
- `z = y + 3`
- `w = z ** 2`

Conte quantos `grad_fn` existem no caminho de `w` at√© `x` (incluindo w.grad_fn) e armazene em `num_operations`. (Resposta: 3 - PowBackward, AddBackward, MulBackward)
</Exercise>

<Exercise id="ex-prevent-gradient" difficulty="hard">
Dado o c√≥digo abaixo, fa√ßa com que o gradiente N√ÉO flua para `x1`, mas flua normalmente para `x2`:
- `x1 = torch.tensor([2.0], requires_grad=True)`
- `x2 = torch.tensor([3.0], requires_grad=True)`
- Calcule `y = x1 * x2` mas bloqueie o gradiente de x1
- Armazene `x1.grad` em `grad_x1` (deve ser None) e `x2.grad` em `grad_x2` (deve ser 2.0)

Dica: use `.detach()` estrategicamente.
</Exercise>

## Resumo

Neste m√≥dulo voc√™ aprendeu sobre o grafo computacional do PyTorch:

### Conceitos Principais

| Conceito | Descri√ß√£o |
|----------|-----------|
| Grafo Computacional | DAG que registra todas as opera√ß√µes para calcular gradientes |
| `grad_fn` | Refer√™ncia √† fun√ß√£o que criou o tensor |
| `next_functions` | Conex√µes para os inputs da opera√ß√£o |
| Folha (Leaf) | Tensor criado diretamente pelo usu√°rio |
| `retain_grad()` | Guarda gradientes de tensores intermedi√°rios |
| `detach()` | Cria c√≥pia desconectada do grafo |

### Tabela de Controle do Grafo

| M√©todo | Efeito | Uso T√≠pico |
|--------|--------|------------|
| `x.requires_grad_(False)` | Desabilita gradientes | Freezing |
| `x.detach()` | Desconecta do grafo | Targets, m√©tricas |
| `torch.no_grad()` | Bloco sem gradientes | Valida√ß√£o |
| `torch.inference_mode()` | Otimizado para infer√™ncia | Produ√ß√£o |
| `retain_grad()` | Guarda grad intermedi√°rio | Debugging |
| `retain_graph=True` | Mant√©m grafo ap√≥s backward | M√∫ltiplos backwards |

### Armadilhas Comuns

<Callout type="warning">
- Esquecer `requires_grad=True` ‚Üí `grad_fn` ser√° None
- Opera√ß√µes in-place em tensores do grafo ‚Üí Erro no backward
- M√∫ltiplos backwards sem `retain_graph=True` ‚Üí Grafo j√° liberado
- Esperar gradientes em non-leaf ‚Üí Use `retain_grad()`
</Callout>

<Callout type="tip">
**Pr√≥ximo passo**: No pr√≥ximo m√≥dulo, vamos colocar tudo em pr√°tica com exerc√≠cios avan√ßados de gradientes, incluindo gradient clipping, debugging de NaN/Inf, e implementa√ß√£o de training loops completos!
</Callout>
